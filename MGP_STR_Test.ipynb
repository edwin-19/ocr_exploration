{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMl+vNUwikuH+UzRGkejNV9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edwin-19/ocr_exploration/blob/main/MGP_STR_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kRB3HJs2SS6",
        "outputId": "b29341ef-6b30-433a-8488-e27e7ad5c337"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYxsVhpyI2jq",
        "outputId": "576dd980-54eb-4362-f44f-f2fb3fe80db5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AdvancedLiterateMachinery'...\n",
            "remote: Enumerating objects: 779, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 779 (delta 2), reused 17 (delta 2), pack-reused 761\u001b[K\n",
            "Receiving objects: 100% (779/779), 66.35 MiB | 24.21 MiB/s, done.\n",
            "Resolving deltas: 100% (205/205), done.\n",
            "Updating files: 100% (685/685), done.\n",
            "--2023-07-30 07:44:31--  https://github.com/AlibabaResearch/AdvancedLiterateMachinery/releases/download/V1.0.1-ECCV2022-model/mgp_str_tiny_patch4_32_128.pth\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/542606488/14f47d55-9a9f-41a9-9926-6454226a2bef?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230730%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230730T074431Z&X-Amz-Expires=300&X-Amz-Signature=20c27d939074b767980bd2c3a9a781ffdb5d237785a6b08622dbd837f44dc60a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=542606488&response-content-disposition=attachment%3B%20filename%3Dmgp_str_tiny_patch4_32_128.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-07-30 07:44:31--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/542606488/14f47d55-9a9f-41a9-9926-6454226a2bef?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230730%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230730T074431Z&X-Amz-Expires=300&X-Amz-Signature=20c27d939074b767980bd2c3a9a781ffdb5d237785a6b08622dbd837f44dc60a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=542606488&response-content-disposition=attachment%3B%20filename%3Dmgp_str_tiny_patch4_32_128.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84266298 (80M) [application/octet-stream]\n",
            "Saving to: ‘mgp_str_tiny_patch4_32_128.pth’\n",
            "\n",
            "mgp_str_tiny_patch4 100%[===================>]  80.36M   116MB/s    in 0.7s    \n",
            "\n",
            "2023-07-30 07:44:32 (116 MB/s) - ‘mgp_str_tiny_patch4_32_128.pth’ saved [84266298/84266298]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AlibabaResearch/AdvancedLiterateMachinery.git\n",
        "!wget https://github.com/AlibabaResearch/AdvancedLiterateMachinery/releases/download/V1.0.1-ECCV2022-model/mgp_str_tiny_patch4_32_128.pth\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv mgp_str_tiny_patch4_32_128.pth AdvancedLiterateMachinery/OCR/MGP-STR/"
      ],
      "metadata": {
        "id": "PERF2bsdxGL8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd AdvancedLiterateMachinery/OCR/MGP-STR/\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZQspbp_JB5l",
        "outputId": "688d6ff2-6b9d-4ad1-f64e-e72211589fd4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AdvancedLiterateMachinery/OCR/MGP-STR\n",
            "Requirement already satisfied: validators==0.20.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.20.0)\n",
            "Requirement already satisfied: timm==0.4.12 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.4.12)\n",
            "Requirement already satisfied: lmdb==1.2.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.2.1)\n",
            "Requirement already satisfied: pillow==8.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (8.1.0)\n",
            "Requirement already satisfied: nltk==3.6.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (3.6.2)\n",
            "Requirement already satisfied: natsort==7.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (7.1.1)\n",
            "Requirement already satisfied: wand==0.6.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (0.6.7)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (4.31.0)\n",
            "Requirement already satisfied: strsimpy==0.2.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (0.2.1)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from validators==0.20.0->-r requirements.txt (line 1)) (4.4.2)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from timm==0.4.12->-r requirements.txt (line 4)) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.4.12->-r requirements.txt (line 4)) (0.15.2+cu118)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk==3.6.2->-r requirements.txt (line 7)) (8.1.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk==3.6.2->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from nltk==3.6.2->-r requirements.txt (line 7)) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk==3.6.2->-r requirements.txt (line 7)) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 12)) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 12)) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 12)) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 12)) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 12)) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 12)) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 12)) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 12)) (0.3.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers->-r requirements.txt (line 12)) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers->-r requirements.txt (line 12)) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12->-r requirements.txt (line 4)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12->-r requirements.txt (line 4)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12->-r requirements.txt (line 4)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12->-r requirements.txt (line 4)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4->timm==0.4.12->-r requirements.txt (line 4)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4->timm==0.4.12->-r requirements.txt (line 4)) (16.0.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 12)) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 12)) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 12)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 12)) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4->timm==0.4.12->-r requirements.txt (line 4)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->timm==0.4.12->-r requirements.txt (line 4)) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir demo_imgs/attens\n",
        "!python demo.py --Transformer mgp-str \\\n",
        "--TransformerModel=mgp_str_tiny_patch4_3_32_128 --model_dir mgp_str_tiny_patch4_32_128.pth --demo_imgs demo_imgs/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eR6pHH4MJekI",
        "outputId": "b2fa5de7-5db1-4f3a-bcdd-63a722f12078"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USE MGP-STR\n",
            "not load pos_embed\n",
            "not load patch_embed.proj.weight\n",
            "not load patch_embed.proj.bias\n",
            "in_chans 3\n",
            "Loading pre-trained vision transformer weights from https://dl.fbaipublicfiles.com/deit/deit_tiny_distilled_patch16_224-b40b3cf7.pth ...\n",
            "loading pretrained model from mgp_str_tiny_patch4_32_128.pth\n",
            "imgs: demo_imgs/IIIT5k_HOUSE.png\n",
            "2023-07-30 07:52:26.275412: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "char: house 0.9976668357849121\n",
            "bpe: house 0.9983832836151123\n",
            "wp: house 0.9897380471229553\n",
            "============================================================================\n",
            "imgs: demo_imgs/IIT5k_EVERYONE.png\n",
            "char: everyone 0.9980122447013855\n",
            "bpe: everyone 0.6859003305435181\n",
            "wp: every 0.00798854324966669\n",
            "============================================================================\n",
            "imgs: demo_imgs/CUTE80_DAY.png\n",
            "char: day 0.9870021939277649\n",
            "bpe: day 0.9989476203918457\n",
            "wp: day 0.9948988556861877\n",
            "============================================================================\n",
            "imgs: demo_imgs/IIT5k_10.png\n",
            "char: 10 0.9974308013916016\n",
            "bpe: 10 0.9973664283752441\n",
            "wp: 10 0.9954859018325806\n",
            "============================================================================\n",
            "imgs: demo_imgs/IC13_leaves.png\n",
            "char: leaves 0.9995428919792175\n",
            "bpe: leaves 0.987250566482544\n",
            "wp: leave 0.05127573385834694\n",
            "============================================================================\n",
            "imgs: demo_imgs/CUTE80_academy.png\n",
            "char: academy 0.9982953667640686\n",
            "bpe: academy 0.23597805202007294\n",
            "wp: ac 0.004671536851674318\n",
            "============================================================================\n",
            "imgs: demo_imgs/CUTE80_LE.png\n",
            "char: le 0.9574306011199951\n",
            "bpe: le 0.9953874349594116\n",
            "wp: le 0.8168767094612122\n",
            "============================================================================\n",
            "imgs: demo_imgs/CUTE80_BAR.png\n",
            "char: bar 0.9996317625045776\n",
            "bpe: bar 0.9975744485855103\n",
            "wp: bar 0.9919825196266174\n",
            "============================================================================\n",
            "imgs: demo_imgs/CUTE80_7.png\n",
            "char: 7 0.9346611499786377\n",
            "bpe: 7 0.9282334446907043\n",
            "wp: 7 0.9489812850952148\n",
            "============================================================================\n",
            "imgs: demo_imgs/IC13_family.png\n",
            "char: family 0.9944920539855957\n",
            "bpe: family 0.9343292713165283\n",
            "wp: family 0.0032474612817168236\n",
            "============================================================================\n",
            "imgs: demo_imgs/CUTE80_UNIVERSITY.png\n",
            "char: university 0.9726992249488831\n",
            "bpe: university 0.9960740804672241\n",
            "wp: university 0.9846688508987427\n",
            "============================================================================\n",
            "imgs: demo_imgs/CUTE80_CROCODILES.png\n",
            "char: crocodiles 0.9757329821586609\n",
            "bpe: crocodiles 0.8496312499046326\n",
            "wp: crs 0.002890978707000613\n",
            "============================================================================\n",
            "imgs: demo_imgs/CUTE80_KINGDOM.png\n",
            "char: kingdom 0.9981809854507446\n",
            "bpe: kingdom 0.9669740200042725\n",
            "wp: king 0.16511450707912445\n",
            "============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import argparse\n",
        "from models import Model\n",
        "from utils import TokenLabelConverter\n",
        "\n",
        "def get_args(is_train=True):\n",
        "    parser = argparse.ArgumentParser(description='STR')\n",
        "\n",
        "    # for test\n",
        "    parser.add_argument('--eval_data', help='path to evaluation dataset')\n",
        "    parser.add_argument('--benchmark_all_eval', action='store_true', help='evaluate 10 benchmark evaluation datasets')\n",
        "    parser.add_argument('--calculate_infer_time', action='store_true', help='calculate inference timing')\n",
        "    parser.add_argument('--flops', action='store_true', help='calculates approx flops (may not work)')\n",
        "\n",
        "    # for train\n",
        "    parser.add_argument('--exp_name', help='Where to store logs and models')\n",
        "    parser.add_argument('--train_data', required=is_train, help='path to training dataset')\n",
        "    parser.add_argument('--valid_data', required=is_train, help='path to validation dataset')\n",
        "    parser.add_argument('--manualSeed', type=int, default=1111, help='for random seed setting')\n",
        "    parser.add_argument('--workers', type=int, help='number of data loading workers. Use -1 to use all cores.', default=4)\n",
        "    parser.add_argument('--batch_size', type=int, default=192, help='input batch size')\n",
        "    parser.add_argument('--num_iter', type=int, default=300000, help='number of iterations to train for')\n",
        "    parser.add_argument('--valInterval', type=int, default=2000, help='Interval between each validation')\n",
        "    parser.add_argument('--saved_model', default='mgp_str_tiny_patch4_32_128.pth', help=\"path to model to continue training\")\n",
        "    parser.add_argument('--saved_path', default='./saved_models', help=\"path to save\")\n",
        "    parser.add_argument('--FT', action='store_true', help='whether to do fine-tuning')\n",
        "    parser.add_argument('--sgd', action='store_true', help='Whether to use SGD (default is Adadelta)')\n",
        "    parser.add_argument('--adam', action='store_true', help='Whether to use adam (default is Adadelta)')\n",
        "    parser.add_argument('--lr', type=float, default=1, help='learning rate, default=1.0 for Adadelta')\n",
        "    parser.add_argument('--beta1', type=float, default=0.9, help='beta1 for adam. default=0.9')\n",
        "    parser.add_argument('--rho', type=float, default=0.95, help='decay rate rho for Adadelta. default=0.95')\n",
        "    parser.add_argument('--eps', type=float, default=1e-8, help='eps for Adadelta. default=1e-8')\n",
        "    parser.add_argument('--grad_clip', type=float, default=5, help='gradient clipping value. default=5')\n",
        "    \"\"\" Data processing \"\"\"\n",
        "    parser.add_argument('--select_data', type=str, default='MJ-ST',\n",
        "                        help='select training data (default is MJ-ST, which means MJ and ST used as training data)')\n",
        "    parser.add_argument('--batch_ratio', type=str, default='0.5-0.5',\n",
        "                        help='assign ratio for each selected data in the batch')\n",
        "    parser.add_argument('--total_data_usage_ratio', type=str, default='1.0',\n",
        "                        help='total data usage ratio, this ratio is multiplied to total number of data.')\n",
        "    parser.add_argument('--batch_max_length', type=int, default=25, help='maximum-label-length')\n",
        "    parser.add_argument('--imgH', type=int, default=32, help='the height of the input image')\n",
        "    parser.add_argument('--imgW', type=int, default=128, help='the width of the input image')\n",
        "    parser.add_argument('--rgb', action='store_true', help='use rgb input')\n",
        "    parser.add_argument('--character', type=str,\n",
        "                        default='0123456789abcdefghijklmnopqrstuvwxyz', help='character label')\n",
        "    parser.add_argument('--sensitive', action='store_true', help='for sensitive character mode')\n",
        "    parser.add_argument('--PAD', action='store_true', help='whether to keep ratio then pad for image resize')\n",
        "    parser.add_argument('--data_filtering_off', action='store_true', help='for data_filtering_off mode')\n",
        "\n",
        "    \"\"\" Model Architecture \"\"\"\n",
        "    parser.add_argument('--Transformer', type=str, required=False, help='Transformer stage. mgp-str|char-str', default='mgp-str')\n",
        "\n",
        "    choices = [\"mgp_str_base_patch4_3_32_128\", \"mgp_str_tiny_patch4_3_32_128\",\n",
        "                \"mgp_str_small_patch4_3_32_128\", \"char_str_base_patch4_3_32_128\"]\n",
        "    parser.add_argument('--TransformerModel', default='mgp_str_tiny_patch4_3_32_128', help='Which mgp_str transformer model', choices=choices)\n",
        "    parser.add_argument('--Transformation', type=str, default='', help='Transformation stage. None|TPS')\n",
        "    parser.add_argument('--FeatureExtraction', type=str, default='',\n",
        "                        help='FeatureExtraction stage. VGG|RCNN|ResNet')\n",
        "    parser.add_argument('--SequenceModeling', type=str, default='', help='SequenceModeling stage. None|BiLSTM')\n",
        "    parser.add_argument('--Prediction', type=str, default='', help='Prediction stage. None|CTC|Attn')\n",
        "    parser.add_argument('--num_fiducial', type=int, default=20, help='number of fiducial points of TPS-STN')\n",
        "    parser.add_argument('--input_channel', type=int, default=3,\n",
        "                        help='the number of input channel of Feature extractor')\n",
        "    parser.add_argument('--output_channel', type=int, default=512,\n",
        "                        help='the number of output channel of Feature extractor')\n",
        "    parser.add_argument('--hidden_size', type=int, default=256, help='the size of the LSTM hidden state')\n",
        "\n",
        "    # selective augmentation\n",
        "    # can choose specific data augmentation\n",
        "    parser.add_argument('--issel_aug', action='store_true', help='Select augs')\n",
        "    parser.add_argument('--sel_prob', type=float, default=1., help='Probability of applying augmentation')\n",
        "    parser.add_argument('--pattern', action='store_true', help='Pattern group')\n",
        "    parser.add_argument('--warp', action='store_true', help='Warp group')\n",
        "    parser.add_argument('--geometry', action='store_true', help='Geometry group')\n",
        "    parser.add_argument('--weather', action='store_true', help='Weather group')\n",
        "    parser.add_argument('--noise', action='store_true', help='Noise group')\n",
        "    parser.add_argument('--blur', action='store_true', help='Blur group')\n",
        "    parser.add_argument('--camera', action='store_true', help='Camera group')\n",
        "    parser.add_argument('--process', action='store_true', help='Image processing routines')\n",
        "\n",
        "    # use cosine learning rate decay\n",
        "    parser.add_argument('--scheduler', action='store_true', help='Use lr scheduler')\n",
        "\n",
        "    parser.add_argument('--intact_prob', type=float, default=0.5, help='Probability of not applying augmentation')\n",
        "    parser.add_argument('--isrand_aug', action='store_true', help='Use RandAug')\n",
        "    parser.add_argument('--augs_num', type=int, default=3, help='Number of data augment groups to apply. 1 to 8.')\n",
        "    parser.add_argument('--augs_mag', type=int, default=None, help='Magnitude of data augment groups to apply. None if random.')\n",
        "\n",
        "    # for comparison to other augmentations\n",
        "    parser.add_argument('--issemantic_aug', action='store_true', help='Use Semantic')\n",
        "    parser.add_argument('--isrotation_aug', action='store_true', help='Use ')\n",
        "    parser.add_argument('--isscatter_aug', action='store_true', help='Use ')\n",
        "    parser.add_argument('--islearning_aug', action='store_true', help='Use ')\n",
        "\n",
        "    # orig paper uses this for fast benchmarking\n",
        "    parser.add_argument('--fast_acc', action='store_true', help='Fast average accuracy computation')\n",
        "\n",
        "    parser.add_argument(\"--local_rank\", type=int, default=-1)\n",
        "    parser.add_argument('--world_size', default=1, type=int,\n",
        "                        help='number of distributed processes')\n",
        "    parser.add_argument('--dist_url', default='env://', help='url used to set up distributed training')\n",
        "    parser.add_argument('--device', default='cuda',\n",
        "                        help='device to use for training / testing')\n",
        "\n",
        "    # mask train\n",
        "    parser.add_argument('--mask_ratio', default=0.5, type=float,\n",
        "                        help='ratio of the visual tokens/patches need be masked')\n",
        "    parser.add_argument(\"--patch_size\", type=int, default=4)\n",
        "\n",
        "    # for eval\n",
        "    parser.add_argument('--eval_img', action='store_true', help='eval imgs dataset')\n",
        "    parser.add_argument('--range', default=None, help=\"start-end for example(800-1000)\")\n",
        "    parser.add_argument('--model_dir', default='')\n",
        "    parser.add_argument('--demo_imgs', default='')\n",
        "\n",
        "    args = parser.parse_args(args=[])\n",
        "    return args"
      ],
      "metadata": {
        "id": "e_ZM_ospLRhI"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cpu')\n",
        "opt = get_args(is_train=False)\n",
        "\n",
        "converter = TokenLabelConverter(opt)\n",
        "opt.num_class = len(converter.character)\n",
        "\n",
        "model = Model(opt)\n",
        "model = torch.nn.DataParallel(model).to(device)\n",
        "model.load_state_dict(torch.load(opt.saved_model, map_location=device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKL0AnAByZ89",
        "outputId": "0abf5697-eb97-4f3f-f5e4-1a447e6e5a9a"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USE MGP-STR\n",
            "not load pos_embed\n",
            "not load patch_embed.proj.weight\n",
            "not load patch_embed.proj.bias\n",
            "in_chans 3\n",
            "Loading pre-trained vision transformer weights from https://dl.fbaipublicfiles.com/deit/deit_tiny_distilled_patch16_224-b40b3cf7.pth ...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx\n",
        "!pip install onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q96rHNx85HeO",
        "outputId": "f4277d4c-cf79-4857-e5c7-68f6dd83a228"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.14.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.22.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.7.1)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.11.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to onnx\n",
        "sample_input = torch.randn(10, 3, opt.imgH, opt.imgW)\n",
        "torch.onnx.export(\n",
        "    model.module, (sample_input), 'sample.onnx',\n",
        "    # input_names['image'], output_names=['attens, char_preds, bpe_preds, wp_preds']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1X9l82l18Pv",
        "outputId": "a7e9aa1e-2cce-4e78-ccbf-478ec3a7a8cf"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/timm/models/layers/patch_embed.py:33: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert H == self.img_size[0] and W == self.img_size[1], \\\n",
            "/content/AdvancedLiterateMachinery/OCR/MGP-STR/modules/mgp_str.py:97: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if is_eval:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "sess = ort.InferenceSession('sample.onnx')"
      ],
      "metadata": {
        "id": "URQi0lu15Zw3"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for out in sess.get_outputs():\n",
        "  print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYG2IYAR5hsN",
        "outputId": "1c708e94-f464-47a9-b235-a429786684bf"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NodeArg(name='1212', type='tensor(float)', shape=['Add1212_dim_0', 'Add1212_dim_1', 38])\n",
            "NodeArg(name='1262', type='tensor(float)', shape=['Add1262_dim_0', 'Add1262_dim_1', 50257])\n",
            "NodeArg(name='1312', type='tensor(float)', shape=['Add1312_dim_0', 'Add1312_dim_1', 30522])\n"
          ]
        }
      ]
    }
  ]
}